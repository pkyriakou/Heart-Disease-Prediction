{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "discrete-yukon",
   "metadata": {},
   "source": [
    "### Heart Disease Predictions\n",
    "\n",
    "**In this notebook we will create three different classification models, train them, test them on unseen data and compare their performance** \\\n",
    "The two models that we will be using are Support Vector Machine, Decision Trees and K-nearest neighbors\n",
    "\n",
    "The models as well as the data split were implemented using [scikit-learn](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "victorian-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets first import the clean data\n",
    "df_heart = pd.read_csv('data/data_clean.csv')\n",
    "df_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experienced-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has (522, 15) examples with (522,) labels\n",
      "Validation set has (156, 15) examples with (156,) labels\n",
      "Test set has (68, 15) examples with (68,) labels\n"
     ]
    }
   ],
   "source": [
    "# Lets now prepare the data in order to be fed to the classifier \n",
    "categorical_columns = df_heart.select_dtypes(include=[object]).columns.values.tolist()\n",
    "numerical_columns = [column for column in df_heart.columns.values.tolist() if column not in categorical_columns][:-1]\n",
    "\n",
    "# Our data has a lot of unlabeled categorical features, thus we will one-hot encode them\n",
    "oh_encoder = OneHotEncoder(drop='first')\n",
    "categ_features_encoded = oh_encoder.fit_transform(df_heart[categorical_columns]).toarray()\n",
    "\n",
    "\n",
    "# First we need to turn the dataset into features and labels and then both into numpy arrays\n",
    "heart_data = np.hstack((df_heart[numerical_columns].to_numpy(), categ_features_encoded))\n",
    "heart_labels = df_heart['HeartDisease'].to_numpy()\n",
    "\n",
    "# Now we split the data into training, validation and test sets with a 70-20-10 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(heart_data, heart_labels, test_size=0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.3, random_state=1)\n",
    "\n",
    "# Now lets check the counts\n",
    "print('Training set has ' + str(x_train.shape) + ' examples with ' + str(y_train.shape) + ' labels')\n",
    "print('Validation set has ' + str(x_val.shape) + ' examples with ' + str(y_val.shape) + ' labels')\n",
    "print('Test set has ' + str(x_test.shape) + ' examples with ' + str(y_test.shape) + ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spatial-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method which receives hyperparameters, training set and data for prediction \n",
    "# The method initializaes an svm model with the given hyperparameters, fits the traiing data \n",
    "# and predicts labels for the prediction data\n",
    "def fit_predict_svm(hyper_params, x_train, y_train, x_predict):\n",
    "    svm_clf = svm.SVC(C=hyper_params[0], kernel=hyper_params[1])  # Initialize the model\n",
    "    svm_clf.fit(x_train, y_train)  # Train the model using the training data\n",
    "    predictions = svm_clf.predict(x_predict)  # Predict labels using trained model\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Method which received true labels, predictions and an evaluation metric and returns the model's score on that metric \n",
    "def evaluation_score(y, predictions, metric='acc'):\n",
    "    if metric == 'acc':\n",
    "        return accuracy_score(y, predictions)\n",
    "    elif metric == 'f1':\n",
    "        return f1_score(y, predictions)\n",
    "    elif metric == 'precission':\n",
    "        return precision_score(y, predictions)\n",
    "    else:\n",
    "        return recall_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prescribed-october",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best svm config (regularization parameter, kernel): (0.1, 'linear')\n",
      "\n",
      "Below the test performance of the above config can be seen:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Disease       0.87      0.81      0.84        32\n",
      "Heart Disease       0.84      0.89      0.86        36\n",
      "\n",
      "     accuracy                           0.85        68\n",
      "    macro avg       0.85      0.85      0.85        68\n",
      " weighted avg       0.85      0.85      0.85        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now that the data has been processed and split, lets create our model, fit the training data to the model and test it\n",
    "# We will begin with the SVM model\n",
    "\n",
    "# We begin with a hyperparameter search to find the best performing config for this dataset\n",
    "best_score = 0\n",
    "for reg in [0.1, 0.3, 0.6, 1, 1.5, 2]:  # Values for the regularization parameter C\n",
    "    for kernl in ['linear', 'poly', 'rbf']:  # Different kernels that can be used\n",
    "        val_predictions = fit_predict_svm((reg, kernl), x_train, y_train, x_val)\n",
    "        \n",
    "        score = evaluation_score(y_val, val_predictions, 'recall')  # We chose recall to prioritise the false negatives\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_hp = (reg, kernl)\n",
    "            best_score = score\n",
    "\n",
    "print('This is the best svm config (regularization parameter, kernel):', best_hp)\n",
    "print()\n",
    "print('Below the test performance of the above config can be seen:')\n",
    "print(classification_report(y_test, fit_predict_svm(best_hp, x_train, y_train, x_test), \n",
    "                            target_names = ['No Disease', 'Heart Disease']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "northern-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below the test performance of the decision tree can be seen:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Disease       0.73      0.75      0.74        32\n",
      "Heart Disease       0.77      0.75      0.76        36\n",
      "\n",
      "     accuracy                           0.75        68\n",
      "    macro avg       0.75      0.75      0.75        68\n",
      " weighted avg       0.75      0.75      0.75        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will now train and predict with the decision tree model\n",
    "\n",
    "# Method which receives hyperparameters, training set and data for prediction \n",
    "# The method initializaes a decision tree model with the given hyperparameters, fits the training data \n",
    "# and predicts labels for the prediction data\n",
    "def fit_predict_dtree(hyper_params, x_train, y_train, x_predict):\n",
    "    tree_clf = DecisionTreeClassifier(random_state=hyper_params[0])  # Initialize the model\n",
    "    tree_clf.fit(x_train, y_train)  # Train the model using the training data\n",
    "    predictions = tree_clf.predict(x_predict)  # Predict labels using trained model\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Decision trees dont have many hyperpramaters that are sensible to vary, thus we wont perform an automated\n",
    "# hyperparameter search \n",
    "print('Below the test performance of the decision tree can be seen:')\n",
    "print(classification_report(y_test, fit_predict_dtree((0,), x_train, y_train, x_test), \n",
    "                            target_names = ['No Disease', 'Heart Disease']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "equal-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below the test performance of the nearest neighbor classifier can be seen:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Disease       0.71      0.84      0.77        32\n",
      "Heart Disease       0.83      0.69      0.76        36\n",
      "\n",
      "     accuracy                           0.76        68\n",
      "    macro avg       0.77      0.77      0.76        68\n",
      " weighted avg       0.78      0.76      0.76        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will now train and make predictions using the K-nearest neighbors model\n",
    "\n",
    "# Method which receives hyperparameters, training set and data for prediction \n",
    "# The method initializaes a decision tree model with the given hyperparameters, fits the training data \n",
    "# and predicts labels for the prediction data\n",
    "def fit_predict_knn(hyper_params, x_train, y_train, x_predict):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=hyper_params[0], weights=hyper_params[1])  # Initialize the model\n",
    "    knn_clf.fit(x_train, y_train)  # Train the model using the training data\n",
    "    predictions = knn_clf.predict(x_predict)  # Predict labels using trained model\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Again we will not do an automatic hyperparameter search\n",
    "print('Below the test performance of the nearest neighbor classifier can be seen:')\n",
    "print(classification_report(y_test, fit_predict_knn((9,'distance'), x_train, y_train, x_test), \n",
    "                            target_names = ['No Disease', 'Heart Disease']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
